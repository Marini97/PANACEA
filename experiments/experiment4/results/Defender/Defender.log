PRISM-games
===========

Version: 3.2.1 (based on PRISM 4.8.dev)
Date: Thu Jul 18 14:39:17 CEST 2024
Hostname: tuf
Memory limits: cudd=2g, java(heap)=12g
Command line: prism-games -javamaxmem 12g -cuddmaxmem 2g experiments/experiment4/prism/Defender.prism experiments/experiment4/prism/defender.props -prop 1 -const 'accesstomysql=0:2,accesstoreverseshell=0:2,accesstosensitivefiles=0:2,accesstoexecutearbitrarycode=0:2,webreconsuccesful=0:2' -exportresults 'experiments/experiment4/results/Defender/Defender.csv:csv' -exportstrat experiments/experiment4/results/Defender/Defender.dot

Parsing model file "experiments/experiment4/prism/Defender.prism"...

Type:        SMG
Modules:     attacker defender
Variables:   sched DataExfiltration AccesstoMySQL AccesstoReverseShell AccesstoSensitiveFiles AccesstoExecuteArbitraryCode WebReconSuccesful WebserverPubliclyExposed VulnerableApacheHTTPServerVersion SOCKS5ProxyActive MisconfiguredApache CGIscriptsenabled UnencryptedFiles

Parsing properties file "experiments/experiment4/prism/defender.props"...

1 property:
(1) <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=0,accesstosensitivefiles=0,accesstoexecutearbitrarycode=0,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=0,accesstosensitivefiles=0,accesstoexecutearbitrarycode=0,webreconsuccesful=0

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.054 secs.
Sorting reachable states list...

Time for model construction: 0.074 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
Prob1 (maxmin) took 1 iterations and 0.003 seconds.
target=256, inf=0, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.011 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
Prob1 (maxmax) took 1 iterations and 0.0 seconds.
target=256, inf=0, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: 0.0

Time for model checking: 0.029 seconds.

Result: 0.0 (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=0,accesstosensitivefiles=0,accesstoexecutearbitrarycode=0,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=0,accesstosensitivefiles=0,accesstoexecutearbitrarycode=0,webreconsuccesful=1

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.011 secs.
Sorting reachable states list...

Time for model construction: 0.012 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=256, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.001 seconds.
Expected reachability took 0.001 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=256, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.002 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=0,accesstosensitivefiles=0,accesstoexecutearbitrarycode=0,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=0,accesstosensitivefiles=0,accesstoexecutearbitrarycode=0,webreconsuccesful=2

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.01 secs.
Sorting reachable states list...

Time for model construction: 0.011 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
Prob1 (maxmin) took 1 iterations and 0.0 seconds.
target=256, inf=0, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
Prob1 (maxmax) took 1 iterations and 0.0 seconds.
target=256, inf=0, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.001 seconds.

Value in the initial state: 0.0

Time for model checking: 0.002 seconds.

Result: 0.0 (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=0,accesstosensitivefiles=0,accesstoexecutearbitrarycode=1,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=0,accesstosensitivefiles=0,accesstoexecutearbitrarycode=1,webreconsuccesful=0

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.008 secs.
Sorting reachable states list...

Time for model construction: 0.009 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=256, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.001 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=256, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.002 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=0,accesstosensitivefiles=0,accesstoexecutearbitrarycode=1,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=0,accesstosensitivefiles=0,accesstoexecutearbitrarycode=1,webreconsuccesful=1

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.009 secs.
Sorting reachable states list...

Time for model construction: 0.01 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=256, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=256, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.001 seconds.

Value in the initial state: Infinity

Time for model checking: 0.002 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=0,accesstosensitivefiles=0,accesstoexecutearbitrarycode=1,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=0,accesstosensitivefiles=0,accesstoexecutearbitrarycode=1,webreconsuccesful=2

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.008 secs.
Sorting reachable states list...

Time for model construction: 0.008 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=256, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=256, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.001 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=0,accesstosensitivefiles=0,accesstoexecutearbitrarycode=2,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=0,accesstosensitivefiles=0,accesstoexecutearbitrarycode=2,webreconsuccesful=0

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.009 secs.
Sorting reachable states list...

Time for model construction: 0.011 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
Prob1 (maxmin) took 1 iterations and 0.0 seconds.
target=256, inf=0, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
Prob1 (maxmax) took 1 iterations and 0.0 seconds.
target=256, inf=0, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.001 seconds.

Value in the initial state: 0.0

Time for model checking: 0.001 seconds.

Result: 0.0 (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=0,accesstosensitivefiles=0,accesstoexecutearbitrarycode=2,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=0,accesstosensitivefiles=0,accesstoexecutearbitrarycode=2,webreconsuccesful=1

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.011 secs.
Sorting reachable states list...

Time for model construction: 0.012 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=256, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=256, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.001 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=0,accesstosensitivefiles=0,accesstoexecutearbitrarycode=2,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=0,accesstosensitivefiles=0,accesstoexecutearbitrarycode=2,webreconsuccesful=2

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.019 secs.
Sorting reachable states list...

Time for model construction: 0.019 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
Prob1 (maxmin) took 1 iterations and 0.0 seconds.
target=256, inf=0, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
Prob1 (maxmax) took 1 iterations and 0.0 seconds.
target=256, inf=0, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: 0.0

Time for model checking: 0.001 seconds.

Result: 0.0 (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=0,accesstosensitivefiles=1,accesstoexecutearbitrarycode=0,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=0,accesstosensitivefiles=1,accesstoexecutearbitrarycode=0,webreconsuccesful=0

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.008 secs.
Sorting reachable states list...

Time for model construction: 0.008 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
Prob1 (maxmin) took 3 iterations and 0.008 seconds.
target=128, inf=0, rest=128
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.003 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.001 seconds.
Expected reachability took 0.013 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
Prob1 (maxmax) took 3 iterations and 0.001 seconds.
target=128, inf=0, rest=128
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 5 iterations and 0.001 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 3 iterations and 0.0 seconds.
Expected reachability took 0.002 seconds.

Value in the initial state: 60.0

Time for model checking: 0.017 seconds.

Result: 60.0 (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=0,accesstosensitivefiles=1,accesstoexecutearbitrarycode=0,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=0,accesstosensitivefiles=1,accesstoexecutearbitrarycode=0,webreconsuccesful=1

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.009 secs.
Sorting reachable states list...

Time for model construction: 0.01 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=256, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=256, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.001 seconds.

Value in the initial state: Infinity

Time for model checking: 0.001 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=0,accesstosensitivefiles=1,accesstoexecutearbitrarycode=0,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=0,accesstosensitivefiles=1,accesstoexecutearbitrarycode=0,webreconsuccesful=2

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.006 secs.
Sorting reachable states list...

Time for model construction: 0.006 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
Prob1 (maxmin) took 3 iterations and 0.001 seconds.
target=128, inf=0, rest=128
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.001 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.002 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
Prob1 (maxmax) took 3 iterations and 0.001 seconds.
target=128, inf=0, rest=128
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 5 iterations and 0.001 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 3 iterations and 0.0 seconds.
Expected reachability took 0.002 seconds.

Value in the initial state: 60.0

Time for model checking: 0.005 seconds.

Result: 60.0 (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=0,accesstosensitivefiles=1,accesstoexecutearbitrarycode=1,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=0,accesstosensitivefiles=1,accesstoexecutearbitrarycode=1,webreconsuccesful=0

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.008 secs.
Sorting reachable states list...

Time for model construction: 0.009 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=256, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.001 seconds.
Expected reachability took 0.001 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=256, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.001 seconds.

Value in the initial state: Infinity

Time for model checking: 0.002 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=0,accesstosensitivefiles=1,accesstoexecutearbitrarycode=1,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=0,accesstosensitivefiles=1,accesstoexecutearbitrarycode=1,webreconsuccesful=1

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.008 secs.
Sorting reachable states list...

Time for model construction: 0.009 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=256, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=256, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.001 seconds.

Value in the initial state: Infinity

Time for model checking: 0.002 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=0,accesstosensitivefiles=1,accesstoexecutearbitrarycode=1,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=0,accesstosensitivefiles=1,accesstoexecutearbitrarycode=1,webreconsuccesful=2

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.008 secs.
Sorting reachable states list...

Time for model construction: 0.009 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=256, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=256, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.001 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=0,accesstosensitivefiles=1,accesstoexecutearbitrarycode=2,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=0,accesstosensitivefiles=1,accesstoexecutearbitrarycode=2,webreconsuccesful=0

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.006 secs.
Sorting reachable states list...

Time for model construction: 0.007 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
Prob1 (maxmin) took 3 iterations and 0.001 seconds.
target=128, inf=0, rest=128
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.001 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.002 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
Prob1 (maxmax) took 3 iterations and 0.001 seconds.
target=128, inf=0, rest=128
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 5 iterations and 0.001 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 3 iterations and 0.0 seconds.
Expected reachability took 0.002 seconds.

Value in the initial state: 60.0

Time for model checking: 0.005 seconds.

Result: 60.0 (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=0,accesstosensitivefiles=1,accesstoexecutearbitrarycode=2,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=0,accesstosensitivefiles=1,accesstoexecutearbitrarycode=2,webreconsuccesful=1

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.007 secs.
Sorting reachable states list...

Time for model construction: 0.007 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=256, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.001 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=256, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.001 seconds.
Expected reachability took 0.001 seconds.

Value in the initial state: Infinity

Time for model checking: 0.002 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=0,accesstosensitivefiles=1,accesstoexecutearbitrarycode=2,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=0,accesstosensitivefiles=1,accesstoexecutearbitrarycode=2,webreconsuccesful=2

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.008 secs.
Sorting reachable states list...

Time for model construction: 0.009 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
Prob1 (maxmin) took 3 iterations and 0.001 seconds.
target=128, inf=0, rest=128
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.002 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
Prob1 (maxmax) took 3 iterations and 0.0 seconds.
target=128, inf=0, rest=128
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 5 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 3 iterations and 0.005 seconds.
Expected reachability took 0.006 seconds.

Value in the initial state: 60.0

Time for model checking: 0.008 seconds.

Result: 60.0 (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=0,accesstosensitivefiles=2,accesstoexecutearbitrarycode=0,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=0,accesstosensitivefiles=2,accesstoexecutearbitrarycode=0,webreconsuccesful=0

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
Prob1 (maxmin) took 1 iterations and 0.0 seconds.
target=128, inf=0, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
Prob1 (maxmax) took 1 iterations and 0.0 seconds.
target=128, inf=0, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.001 seconds.

Value in the initial state: 0.0

Time for model checking: 0.001 seconds.

Result: 0.0 (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=0,accesstosensitivefiles=2,accesstoexecutearbitrarycode=0,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=0,accesstosensitivefiles=2,accesstoexecutearbitrarycode=0,webreconsuccesful=1

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.007 secs.
Sorting reachable states list...

Time for model construction: 0.007 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=128, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=128, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.001 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=0,accesstosensitivefiles=2,accesstoexecutearbitrarycode=0,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=0,accesstosensitivefiles=2,accesstoexecutearbitrarycode=0,webreconsuccesful=2

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.006 secs.
Sorting reachable states list...

Time for model construction: 0.006 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
Prob1 (maxmin) took 1 iterations and 0.0 seconds.
target=128, inf=0, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.001 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
Prob1 (maxmax) took 1 iterations and 0.0 seconds.
target=128, inf=0, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: 0.0

Time for model checking: 0.001 seconds.

Result: 0.0 (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=0,accesstosensitivefiles=2,accesstoexecutearbitrarycode=1,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=0,accesstosensitivefiles=2,accesstoexecutearbitrarycode=1,webreconsuccesful=0

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.006 secs.
Sorting reachable states list...

Time for model construction: 0.007 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=128, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.001 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=128, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.001 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=0,accesstosensitivefiles=2,accesstoexecutearbitrarycode=1,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=0,accesstosensitivefiles=2,accesstoexecutearbitrarycode=1,webreconsuccesful=1

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.007 secs.
Sorting reachable states list...

Time for model construction: 0.007 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=128, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=128, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.001 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=0,accesstosensitivefiles=2,accesstoexecutearbitrarycode=1,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=0,accesstosensitivefiles=2,accesstoexecutearbitrarycode=1,webreconsuccesful=2

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.006 secs.
Sorting reachable states list...

Time for model construction: 0.006 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=128, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=128, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.001 seconds.

Value in the initial state: Infinity

Time for model checking: 0.001 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=0,accesstosensitivefiles=2,accesstoexecutearbitrarycode=2,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=0,accesstosensitivefiles=2,accesstoexecutearbitrarycode=2,webreconsuccesful=0

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.006 secs.
Sorting reachable states list...

Time for model construction: 0.006 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
Prob1 (maxmin) took 1 iterations and 0.0 seconds.
target=128, inf=0, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.001 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
Prob1 (maxmax) took 1 iterations and 0.0 seconds.
target=128, inf=0, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: 0.0

Time for model checking: 0.001 seconds.

Result: 0.0 (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=0,accesstosensitivefiles=2,accesstoexecutearbitrarycode=2,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=0,accesstosensitivefiles=2,accesstoexecutearbitrarycode=2,webreconsuccesful=1

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.006 secs.
Sorting reachable states list...

Time for model construction: 0.006 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=128, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.001 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.001 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=128, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.001 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=0,accesstosensitivefiles=2,accesstoexecutearbitrarycode=2,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=0,accesstosensitivefiles=2,accesstoexecutearbitrarycode=2,webreconsuccesful=2

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.006 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
Prob1 (maxmin) took 1 iterations and 0.0 seconds.
target=128, inf=0, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.001 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
Prob1 (maxmax) took 1 iterations and 0.0 seconds.
target=128, inf=0, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: 0.0

Time for model checking: 0.002 seconds.

Result: 0.0 (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=1,accesstosensitivefiles=0,accesstoexecutearbitrarycode=0,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=1,accesstosensitivefiles=0,accesstoexecutearbitrarycode=0,webreconsuccesful=0

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.006 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=256, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=256, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=1,accesstosensitivefiles=0,accesstoexecutearbitrarycode=0,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=1,accesstosensitivefiles=0,accesstoexecutearbitrarycode=0,webreconsuccesful=1

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.011 secs.
Sorting reachable states list...

Time for model construction: 0.011 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=256, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=256, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.001 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=1,accesstosensitivefiles=0,accesstoexecutearbitrarycode=0,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=1,accesstosensitivefiles=0,accesstoexecutearbitrarycode=0,webreconsuccesful=2

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.006 secs.
Sorting reachable states list...

Time for model construction: 0.006 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=256, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=256, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.001 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=1,accesstosensitivefiles=0,accesstoexecutearbitrarycode=1,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=1,accesstosensitivefiles=0,accesstoexecutearbitrarycode=1,webreconsuccesful=0

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=256, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.001 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=256, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.001 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=1,accesstosensitivefiles=0,accesstoexecutearbitrarycode=1,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=1,accesstosensitivefiles=0,accesstoexecutearbitrarycode=1,webreconsuccesful=1

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.006 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=256, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=256, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.001 seconds.

Value in the initial state: Infinity

Time for model checking: 0.001 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=1,accesstosensitivefiles=0,accesstoexecutearbitrarycode=1,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=1,accesstosensitivefiles=0,accesstoexecutearbitrarycode=1,webreconsuccesful=2

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.006 secs.
Sorting reachable states list...

Time for model construction: 0.006 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=256, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=256, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.001 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=1,accesstosensitivefiles=0,accesstoexecutearbitrarycode=2,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=1,accesstosensitivefiles=0,accesstoexecutearbitrarycode=2,webreconsuccesful=0

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.007 secs.
Sorting reachable states list...

Time for model construction: 0.007 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=256, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=256, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=1,accesstosensitivefiles=0,accesstoexecutearbitrarycode=2,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=1,accesstosensitivefiles=0,accesstoexecutearbitrarycode=2,webreconsuccesful=1

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.006 secs.
Sorting reachable states list...

Time for model construction: 0.006 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=256, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=256, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=1,accesstosensitivefiles=0,accesstoexecutearbitrarycode=2,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=1,accesstosensitivefiles=0,accesstoexecutearbitrarycode=2,webreconsuccesful=2

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=256, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=256, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.001 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=1,accesstosensitivefiles=1,accesstoexecutearbitrarycode=0,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=1,accesstosensitivefiles=1,accesstoexecutearbitrarycode=0,webreconsuccesful=0

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.006 secs.
Sorting reachable states list...

Time for model construction: 0.006 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=256, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=256, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.001 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=1,accesstosensitivefiles=1,accesstoexecutearbitrarycode=0,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=1,accesstosensitivefiles=1,accesstoexecutearbitrarycode=0,webreconsuccesful=1

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.025 secs.
Sorting reachable states list...

Time for model construction: 0.025 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=256, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=256, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=1,accesstosensitivefiles=1,accesstoexecutearbitrarycode=0,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=1,accesstosensitivefiles=1,accesstoexecutearbitrarycode=0,webreconsuccesful=2

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.007 secs.
Sorting reachable states list...

Time for model construction: 0.007 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=256, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=256, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.001 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=1,accesstosensitivefiles=1,accesstoexecutearbitrarycode=1,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=1,accesstosensitivefiles=1,accesstoexecutearbitrarycode=1,webreconsuccesful=0

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.008 secs.
Sorting reachable states list...

Time for model construction: 0.008 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=256, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=256, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.001 seconds.

Value in the initial state: Infinity

Time for model checking: 0.001 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=1,accesstosensitivefiles=1,accesstoexecutearbitrarycode=1,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=1,accesstosensitivefiles=1,accesstoexecutearbitrarycode=1,webreconsuccesful=1

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.008 secs.
Sorting reachable states list...

Time for model construction: 0.009 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=256, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.001 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=256, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.001 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=1,accesstosensitivefiles=1,accesstoexecutearbitrarycode=1,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=1,accesstosensitivefiles=1,accesstoexecutearbitrarycode=1,webreconsuccesful=2

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.008 secs.
Sorting reachable states list...

Time for model construction: 0.008 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=256, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=256, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=1,accesstosensitivefiles=1,accesstoexecutearbitrarycode=2,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=1,accesstosensitivefiles=1,accesstoexecutearbitrarycode=2,webreconsuccesful=0

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.011 secs.
Sorting reachable states list...

Time for model construction: 0.011 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=256, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=256, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=1,accesstosensitivefiles=1,accesstoexecutearbitrarycode=2,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=1,accesstosensitivefiles=1,accesstoexecutearbitrarycode=2,webreconsuccesful=1

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.007 secs.
Sorting reachable states list...

Time for model construction: 0.008 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=256, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=256, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=1,accesstosensitivefiles=1,accesstoexecutearbitrarycode=2,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=1,accesstosensitivefiles=1,accesstoexecutearbitrarycode=2,webreconsuccesful=2

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.006 secs.
Sorting reachable states list...

Time for model construction: 0.006 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=256, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=256, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.001 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=1,accesstosensitivefiles=2,accesstoexecutearbitrarycode=0,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=1,accesstosensitivefiles=2,accesstoexecutearbitrarycode=0,webreconsuccesful=0

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.007 secs.
Sorting reachable states list...

Time for model construction: 0.007 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=128, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=128, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.001 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=1,accesstosensitivefiles=2,accesstoexecutearbitrarycode=0,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=1,accesstosensitivefiles=2,accesstoexecutearbitrarycode=0,webreconsuccesful=1

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.006 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=128, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=128, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=1,accesstosensitivefiles=2,accesstoexecutearbitrarycode=0,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=1,accesstosensitivefiles=2,accesstoexecutearbitrarycode=0,webreconsuccesful=2

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.007 secs.
Sorting reachable states list...

Time for model construction: 0.007 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=128, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=128, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.001 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=1,accesstosensitivefiles=2,accesstoexecutearbitrarycode=1,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=1,accesstosensitivefiles=2,accesstoexecutearbitrarycode=1,webreconsuccesful=0

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.007 secs.
Sorting reachable states list...

Time for model construction: 0.007 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=128, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=128, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.001 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=1,accesstosensitivefiles=2,accesstoexecutearbitrarycode=1,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=1,accesstosensitivefiles=2,accesstoexecutearbitrarycode=1,webreconsuccesful=1

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.006 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=128, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=128, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=1,accesstosensitivefiles=2,accesstoexecutearbitrarycode=1,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=1,accesstosensitivefiles=2,accesstoexecutearbitrarycode=1,webreconsuccesful=2

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.011 secs.
Sorting reachable states list...

Time for model construction: 0.012 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=128, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.001 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=128, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.001 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=1,accesstosensitivefiles=2,accesstoexecutearbitrarycode=2,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=1,accesstosensitivefiles=2,accesstoexecutearbitrarycode=2,webreconsuccesful=0

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.006 secs.
Sorting reachable states list...

Time for model construction: 0.006 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=128, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=128, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.001 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=1,accesstosensitivefiles=2,accesstoexecutearbitrarycode=2,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=1,accesstosensitivefiles=2,accesstoexecutearbitrarycode=2,webreconsuccesful=1

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.008 secs.
Sorting reachable states list...

Time for model construction: 0.008 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=128, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.001 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=128, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.001 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=1,accesstosensitivefiles=2,accesstoexecutearbitrarycode=2,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=1,accesstosensitivefiles=2,accesstoexecutearbitrarycode=2,webreconsuccesful=2

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.008 secs.
Sorting reachable states list...

Time for model construction: 0.008 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=128, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=128, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=2,accesstosensitivefiles=0,accesstoexecutearbitrarycode=0,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=2,accesstosensitivefiles=0,accesstoexecutearbitrarycode=0,webreconsuccesful=0

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.006 secs.
Sorting reachable states list...

Time for model construction: 0.006 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
Prob1 (maxmin) took 1 iterations and 0.0 seconds.
target=256, inf=0, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
Prob1 (maxmax) took 1 iterations and 0.0 seconds.
target=256, inf=0, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: 0.0

Time for model checking: 0.0 seconds.

Result: 0.0 (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=2,accesstosensitivefiles=0,accesstoexecutearbitrarycode=0,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=2,accesstosensitivefiles=0,accesstoexecutearbitrarycode=0,webreconsuccesful=1

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.006 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=256, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=256, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.001 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=2,accesstosensitivefiles=0,accesstoexecutearbitrarycode=0,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=2,accesstosensitivefiles=0,accesstoexecutearbitrarycode=0,webreconsuccesful=2

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.006 secs.
Sorting reachable states list...

Time for model construction: 0.006 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
Prob1 (maxmin) took 1 iterations and 0.0 seconds.
target=256, inf=0, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
Prob1 (maxmax) took 1 iterations and 0.0 seconds.
target=256, inf=0, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: 0.0

Time for model checking: 0.0 seconds.

Result: 0.0 (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=2,accesstosensitivefiles=0,accesstoexecutearbitrarycode=1,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=2,accesstosensitivefiles=0,accesstoexecutearbitrarycode=1,webreconsuccesful=0

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.006 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=256, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=256, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=2,accesstosensitivefiles=0,accesstoexecutearbitrarycode=1,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=2,accesstosensitivefiles=0,accesstoexecutearbitrarycode=1,webreconsuccesful=1

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.006 secs.
Sorting reachable states list...

Time for model construction: 0.006 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=256, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.001 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=256, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.001 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=2,accesstosensitivefiles=0,accesstoexecutearbitrarycode=1,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=2,accesstosensitivefiles=0,accesstoexecutearbitrarycode=1,webreconsuccesful=2

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.006 secs.
Sorting reachable states list...

Time for model construction: 0.006 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=256, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=256, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.001 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=2,accesstosensitivefiles=0,accesstoexecutearbitrarycode=2,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=2,accesstosensitivefiles=0,accesstoexecutearbitrarycode=2,webreconsuccesful=0

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.006 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
Prob1 (maxmin) took 1 iterations and 0.0 seconds.
target=256, inf=0, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
Prob1 (maxmax) took 1 iterations and 0.0 seconds.
target=256, inf=0, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: 0.0

Time for model checking: 0.001 seconds.

Result: 0.0 (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=2,accesstosensitivefiles=0,accesstoexecutearbitrarycode=2,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=2,accesstosensitivefiles=0,accesstoexecutearbitrarycode=2,webreconsuccesful=1

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.006 secs.
Sorting reachable states list...

Time for model construction: 0.006 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=256, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=256, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.001 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=2,accesstosensitivefiles=0,accesstoexecutearbitrarycode=2,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=2,accesstosensitivefiles=0,accesstoexecutearbitrarycode=2,webreconsuccesful=2

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.007 secs.
Sorting reachable states list...

Time for model construction: 0.008 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
Prob1 (maxmin) took 1 iterations and 0.0 seconds.
target=256, inf=0, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.001 seconds.
Expected reachability took 0.001 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
Prob1 (maxmax) took 1 iterations and 0.0 seconds.
target=256, inf=0, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: 0.0

Time for model checking: 0.001 seconds.

Result: 0.0 (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=2,accesstosensitivefiles=1,accesstoexecutearbitrarycode=0,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=2,accesstosensitivefiles=1,accesstoexecutearbitrarycode=0,webreconsuccesful=0

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
Prob1 (maxmin) took 3 iterations and 0.0 seconds.
target=128, inf=0, rest=128
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
Prob1 (maxmax) took 3 iterations and 0.0 seconds.
target=128, inf=0, rest=128
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 5 iterations and 0.001 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 3 iterations and 0.0 seconds.
Expected reachability took 0.001 seconds.

Value in the initial state: 60.0

Time for model checking: 0.002 seconds.

Result: 60.0 (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=2,accesstosensitivefiles=1,accesstoexecutearbitrarycode=0,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=2,accesstosensitivefiles=1,accesstoexecutearbitrarycode=0,webreconsuccesful=1

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.016 secs.
Sorting reachable states list...

Time for model construction: 0.017 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=256, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.001 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=256, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.002 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=2,accesstosensitivefiles=1,accesstoexecutearbitrarycode=0,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=2,accesstosensitivefiles=1,accesstoexecutearbitrarycode=0,webreconsuccesful=2

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.006 secs.
Sorting reachable states list...

Time for model construction: 0.006 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
Prob1 (maxmin) took 3 iterations and 0.001 seconds.
target=128, inf=0, rest=128
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.001 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
Prob1 (maxmax) took 3 iterations and 0.0 seconds.
target=128, inf=0, rest=128
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 5 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 3 iterations and 0.001 seconds.
Expected reachability took 0.002 seconds.

Value in the initial state: 60.0

Time for model checking: 0.003 seconds.

Result: 60.0 (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=2,accesstosensitivefiles=1,accesstoexecutearbitrarycode=1,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=2,accesstosensitivefiles=1,accesstoexecutearbitrarycode=1,webreconsuccesful=0

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.008 secs.
Sorting reachable states list...

Time for model construction: 0.009 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=256, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=256, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=2,accesstosensitivefiles=1,accesstoexecutearbitrarycode=1,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=2,accesstosensitivefiles=1,accesstoexecutearbitrarycode=1,webreconsuccesful=1

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.006 secs.
Sorting reachable states list...

Time for model construction: 0.006 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=256, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=256, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.001 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=2,accesstosensitivefiles=1,accesstoexecutearbitrarycode=1,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=2,accesstosensitivefiles=1,accesstoexecutearbitrarycode=1,webreconsuccesful=2

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.006 secs.
Sorting reachable states list...

Time for model construction: 0.006 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=256, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=256, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=2,accesstosensitivefiles=1,accesstoexecutearbitrarycode=2,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=2,accesstosensitivefiles=1,accesstoexecutearbitrarycode=2,webreconsuccesful=0

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.007 secs.
Sorting reachable states list...

Time for model construction: 0.007 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
Prob1 (maxmin) took 3 iterations and 0.0 seconds.
target=128, inf=0, rest=128
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
Prob1 (maxmax) took 3 iterations and 0.001 seconds.
target=128, inf=0, rest=128
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 5 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 3 iterations and 0.0 seconds.
Expected reachability took 0.001 seconds.

Value in the initial state: 60.0

Time for model checking: 0.001 seconds.

Result: 60.0 (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=2,accesstosensitivefiles=1,accesstoexecutearbitrarycode=2,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=2,accesstosensitivefiles=1,accesstoexecutearbitrarycode=2,webreconsuccesful=1

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.006 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=256, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=256, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.001 seconds.

Value in the initial state: Infinity

Time for model checking: 0.001 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=2,accesstosensitivefiles=1,accesstoexecutearbitrarycode=2,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=2,accesstosensitivefiles=1,accesstoexecutearbitrarycode=2,webreconsuccesful=2

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.006 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
Prob1 (maxmin) took 3 iterations and 0.0 seconds.
target=128, inf=0, rest=128
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
Prob1 (maxmax) took 3 iterations and 0.0 seconds.
target=128, inf=0, rest=128
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 5 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 3 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: 60.0

Time for model checking: 0.001 seconds.

Result: 60.0 (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=2,accesstosensitivefiles=2,accesstoexecutearbitrarycode=0,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=2,accesstosensitivefiles=2,accesstoexecutearbitrarycode=0,webreconsuccesful=0

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
Prob1 (maxmin) took 1 iterations and 0.0 seconds.
target=128, inf=0, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
Prob1 (maxmax) took 1 iterations and 0.0 seconds.
target=128, inf=0, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: 0.0

Time for model checking: 0.001 seconds.

Result: 0.0 (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=2,accesstosensitivefiles=2,accesstoexecutearbitrarycode=0,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=2,accesstosensitivefiles=2,accesstoexecutearbitrarycode=0,webreconsuccesful=1

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=128, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=128, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=2,accesstosensitivefiles=2,accesstoexecutearbitrarycode=0,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=2,accesstosensitivefiles=2,accesstoexecutearbitrarycode=0,webreconsuccesful=2

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.006 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
Prob1 (maxmin) took 1 iterations and 0.0 seconds.
target=128, inf=0, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
Prob1 (maxmax) took 1 iterations and 0.001 seconds.
target=128, inf=0, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.001 seconds.

Value in the initial state: 0.0

Time for model checking: 0.001 seconds.

Result: 0.0 (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=2,accesstosensitivefiles=2,accesstoexecutearbitrarycode=1,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=2,accesstosensitivefiles=2,accesstoexecutearbitrarycode=1,webreconsuccesful=0

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=128, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=128, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=2,accesstosensitivefiles=2,accesstoexecutearbitrarycode=1,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=2,accesstosensitivefiles=2,accesstoexecutearbitrarycode=1,webreconsuccesful=1

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=128, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=128, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=2,accesstosensitivefiles=2,accesstoexecutearbitrarycode=1,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=2,accesstosensitivefiles=2,accesstoexecutearbitrarycode=1,webreconsuccesful=2

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=128, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=128, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=2,accesstosensitivefiles=2,accesstoexecutearbitrarycode=2,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=2,accesstosensitivefiles=2,accesstoexecutearbitrarycode=2,webreconsuccesful=0

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.009 secs.
Sorting reachable states list...

Time for model construction: 0.009 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
Prob1 (maxmin) took 1 iterations and 0.0 seconds.
target=128, inf=0, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
Prob1 (maxmax) took 1 iterations and 0.0 seconds.
target=128, inf=0, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: 0.0

Time for model checking: 0.0 seconds.

Result: 0.0 (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=2,accesstosensitivefiles=2,accesstoexecutearbitrarycode=2,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=2,accesstosensitivefiles=2,accesstoexecutearbitrarycode=2,webreconsuccesful=1

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.006 secs.
Sorting reachable states list...

Time for model construction: 0.006 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=128, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=128, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=0,accesstoreverseshell=2,accesstosensitivefiles=2,accesstoexecutearbitrarycode=2,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=0,accesstoreverseshell=2,accesstosensitivefiles=2,accesstoexecutearbitrarycode=2,webreconsuccesful=2

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.006 secs.
Sorting reachable states list...

Time for model construction: 0.006 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
Prob1 (maxmin) took 1 iterations and 0.0 seconds.
target=128, inf=0, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
Prob1 (maxmax) took 1 iterations and 0.0 seconds.
target=128, inf=0, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: 0.0

Time for model checking: 0.0 seconds.

Result: 0.0 (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=0,accesstosensitivefiles=0,accesstoexecutearbitrarycode=0,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=0,accesstosensitivefiles=0,accesstoexecutearbitrarycode=0,webreconsuccesful=0

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
Prob1 (maxmin) took 3 iterations and 0.0 seconds.
target=128, inf=0, rest=128
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
Prob1 (maxmax) took 3 iterations and 0.0 seconds.
target=128, inf=0, rest=128
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 11 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 3 iterations and 0.001 seconds.
Expected reachability took 0.001 seconds.

Value in the initial state: 200.0

Time for model checking: 0.002 seconds.

Result: 200.0 (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=0,accesstosensitivefiles=0,accesstoexecutearbitrarycode=0,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=0,accesstosensitivefiles=0,accesstoexecutearbitrarycode=0,webreconsuccesful=1

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.015 secs.
Sorting reachable states list...

Time for model construction: 0.016 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=256, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=256, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.001 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=0,accesstosensitivefiles=0,accesstoexecutearbitrarycode=0,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=0,accesstosensitivefiles=0,accesstoexecutearbitrarycode=0,webreconsuccesful=2

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
Prob1 (maxmin) took 3 iterations and 0.0 seconds.
target=128, inf=0, rest=128
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
Prob1 (maxmax) took 3 iterations and 0.001 seconds.
target=128, inf=0, rest=128
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 11 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 3 iterations and 0.001 seconds.
Expected reachability took 0.002 seconds.

Value in the initial state: 200.0

Time for model checking: 0.003 seconds.

Result: 200.0 (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=0,accesstosensitivefiles=0,accesstoexecutearbitrarycode=1,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=0,accesstosensitivefiles=0,accesstoexecutearbitrarycode=1,webreconsuccesful=0

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.006 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=256, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=256, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.001 seconds.

Value in the initial state: Infinity

Time for model checking: 0.001 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=0,accesstosensitivefiles=0,accesstoexecutearbitrarycode=1,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=0,accesstosensitivefiles=0,accesstoexecutearbitrarycode=1,webreconsuccesful=1

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.006 secs.
Sorting reachable states list...

Time for model construction: 0.006 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=256, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=256, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.001 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=0,accesstosensitivefiles=0,accesstoexecutearbitrarycode=1,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=0,accesstosensitivefiles=0,accesstoexecutearbitrarycode=1,webreconsuccesful=2

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=256, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=256, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=0,accesstosensitivefiles=0,accesstoexecutearbitrarycode=2,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=0,accesstosensitivefiles=0,accesstoexecutearbitrarycode=2,webreconsuccesful=0

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
Prob1 (maxmin) took 3 iterations and 0.0 seconds.
target=128, inf=0, rest=128
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.001 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
Prob1 (maxmax) took 3 iterations and 0.0 seconds.
target=128, inf=0, rest=128
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 11 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 3 iterations and 0.001 seconds.
Expected reachability took 0.001 seconds.

Value in the initial state: 200.0

Time for model checking: 0.002 seconds.

Result: 200.0 (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=0,accesstosensitivefiles=0,accesstoexecutearbitrarycode=2,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=0,accesstosensitivefiles=0,accesstoexecutearbitrarycode=2,webreconsuccesful=1

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.006 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=256, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=256, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=0,accesstosensitivefiles=0,accesstoexecutearbitrarycode=2,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=0,accesstosensitivefiles=0,accesstoexecutearbitrarycode=2,webreconsuccesful=2

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
Prob1 (maxmin) took 3 iterations and 0.001 seconds.
target=128, inf=0, rest=128
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.001 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
Prob1 (maxmax) took 3 iterations and 0.0 seconds.
target=128, inf=0, rest=128
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 11 iterations and 0.001 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 3 iterations and 0.0 seconds.
Expected reachability took 0.001 seconds.

Value in the initial state: 200.0

Time for model checking: 0.002 seconds.

Result: 200.0 (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=0,accesstosensitivefiles=1,accesstoexecutearbitrarycode=0,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=0,accesstosensitivefiles=1,accesstoexecutearbitrarycode=0,webreconsuccesful=0

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.006 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
Prob1 (maxmin) took 5 iterations and 0.001 seconds.
target=64, inf=0, rest=192
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.001 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
Prob1 (maxmax) took 5 iterations and 0.001 seconds.
target=64, inf=0, rest=192
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 11 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 5 iterations and 0.0 seconds.
Expected reachability took 0.002 seconds.

Value in the initial state: 260.0

Time for model checking: 0.003 seconds.

Result: 260.0 (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=0,accesstosensitivefiles=1,accesstoexecutearbitrarycode=0,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=0,accesstosensitivefiles=1,accesstoexecutearbitrarycode=0,webreconsuccesful=1

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.017 secs.
Sorting reachable states list...

Time for model construction: 0.017 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=256, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=256, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.001 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=0,accesstosensitivefiles=1,accesstoexecutearbitrarycode=0,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=0,accesstosensitivefiles=1,accesstoexecutearbitrarycode=0,webreconsuccesful=2

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.007 secs.
Sorting reachable states list...

Time for model construction: 0.008 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
Prob1 (maxmin) took 5 iterations and 0.002 seconds.
target=64, inf=0, rest=192
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.002 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
Prob1 (maxmax) took 5 iterations and 0.001 seconds.
target=64, inf=0, rest=192
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 11 iterations and 0.001 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 5 iterations and 0.0 seconds.
Expected reachability took 0.002 seconds.

Value in the initial state: 260.0

Time for model checking: 0.005 seconds.

Result: 260.0 (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=0,accesstosensitivefiles=1,accesstoexecutearbitrarycode=1,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=0,accesstosensitivefiles=1,accesstoexecutearbitrarycode=1,webreconsuccesful=0

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.013 secs.
Sorting reachable states list...

Time for model construction: 0.013 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=256, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=256, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.001 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=0,accesstosensitivefiles=1,accesstoexecutearbitrarycode=1,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=0,accesstosensitivefiles=1,accesstoexecutearbitrarycode=1,webreconsuccesful=1

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.008 secs.
Sorting reachable states list...

Time for model construction: 0.008 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=256, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=256, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.001 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=0,accesstosensitivefiles=1,accesstoexecutearbitrarycode=1,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=0,accesstosensitivefiles=1,accesstoexecutearbitrarycode=1,webreconsuccesful=2

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.01 secs.
Sorting reachable states list...

Time for model construction: 0.01 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=256, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=256, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.002 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=0,accesstosensitivefiles=1,accesstoexecutearbitrarycode=2,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=0,accesstosensitivefiles=1,accesstoexecutearbitrarycode=2,webreconsuccesful=0

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.011 secs.
Sorting reachable states list...

Time for model construction: 0.012 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
Prob1 (maxmin) took 5 iterations and 0.002 seconds.
target=64, inf=0, rest=192
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.002 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
Prob1 (maxmax) took 5 iterations and 0.001 seconds.
target=64, inf=0, rest=192
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 11 iterations and 0.001 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 5 iterations and 0.0 seconds.
Expected reachability took 0.002 seconds.

Value in the initial state: 260.0

Time for model checking: 0.004 seconds.

Result: 260.0 (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=0,accesstosensitivefiles=1,accesstoexecutearbitrarycode=2,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=0,accesstosensitivefiles=1,accesstoexecutearbitrarycode=2,webreconsuccesful=1

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.01 secs.
Sorting reachable states list...

Time for model construction: 0.011 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=256, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=256, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=0,accesstosensitivefiles=1,accesstoexecutearbitrarycode=2,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=0,accesstosensitivefiles=1,accesstoexecutearbitrarycode=2,webreconsuccesful=2

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.009 secs.
Sorting reachable states list...

Time for model construction: 0.009 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
Prob1 (maxmin) took 5 iterations and 0.0 seconds.
target=64, inf=0, rest=192
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.001 seconds.
Expected reachability took 0.001 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
Prob1 (maxmax) took 5 iterations and 0.001 seconds.
target=64, inf=0, rest=192
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 11 iterations and 0.001 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 5 iterations and 0.0 seconds.
Expected reachability took 0.002 seconds.

Value in the initial state: 260.0

Time for model checking: 0.005 seconds.

Result: 260.0 (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=0,accesstosensitivefiles=2,accesstoexecutearbitrarycode=0,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=0,accesstosensitivefiles=2,accesstoexecutearbitrarycode=0,webreconsuccesful=0

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.01 secs.
Sorting reachable states list...

Time for model construction: 0.01 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
Prob1 (maxmin) took 3 iterations and 0.0 seconds.
target=64, inf=0, rest=64
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
Prob1 (maxmax) took 3 iterations and 0.0 seconds.
target=64, inf=0, rest=64
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 9 iterations and 0.002 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 3 iterations and 0.0 seconds.
Expected reachability took 0.002 seconds.

Value in the initial state: 200.0

Time for model checking: 0.002 seconds.

Result: 200.0 (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=0,accesstosensitivefiles=2,accesstoexecutearbitrarycode=0,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=0,accesstosensitivefiles=2,accesstoexecutearbitrarycode=0,webreconsuccesful=1

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.008 secs.
Sorting reachable states list...

Time for model construction: 0.008 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=128, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.001 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=128, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.001 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=0,accesstosensitivefiles=2,accesstoexecutearbitrarycode=0,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=0,accesstosensitivefiles=2,accesstoexecutearbitrarycode=0,webreconsuccesful=2

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.008 secs.
Sorting reachable states list...

Time for model construction: 0.008 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
Prob1 (maxmin) took 3 iterations and 0.0 seconds.
target=64, inf=0, rest=64
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
Prob1 (maxmax) took 3 iterations and 0.0 seconds.
target=64, inf=0, rest=64
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 9 iterations and 0.001 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 3 iterations and 0.001 seconds.
Expected reachability took 0.003 seconds.

Value in the initial state: 200.0

Time for model checking: 0.003 seconds.

Result: 200.0 (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=0,accesstosensitivefiles=2,accesstoexecutearbitrarycode=1,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=0,accesstosensitivefiles=2,accesstoexecutearbitrarycode=1,webreconsuccesful=0

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.011 secs.
Sorting reachable states list...

Time for model construction: 0.012 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=128, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=128, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.001 seconds.

Value in the initial state: Infinity

Time for model checking: 0.001 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=0,accesstosensitivefiles=2,accesstoexecutearbitrarycode=1,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=0,accesstosensitivefiles=2,accesstoexecutearbitrarycode=1,webreconsuccesful=1

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.006 secs.
Sorting reachable states list...

Time for model construction: 0.006 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=128, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=128, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.001 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=0,accesstosensitivefiles=2,accesstoexecutearbitrarycode=1,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=0,accesstosensitivefiles=2,accesstoexecutearbitrarycode=1,webreconsuccesful=2

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.006 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=128, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=128, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=0,accesstosensitivefiles=2,accesstoexecutearbitrarycode=2,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=0,accesstosensitivefiles=2,accesstoexecutearbitrarycode=2,webreconsuccesful=0

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
Prob1 (maxmin) took 3 iterations and 0.0 seconds.
target=64, inf=0, rest=64
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
Prob1 (maxmax) took 3 iterations and 0.001 seconds.
target=64, inf=0, rest=64
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 9 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 3 iterations and 0.0 seconds.
Expected reachability took 0.001 seconds.

Value in the initial state: 200.0

Time for model checking: 0.001 seconds.

Result: 200.0 (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=0,accesstosensitivefiles=2,accesstoexecutearbitrarycode=2,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=0,accesstosensitivefiles=2,accesstoexecutearbitrarycode=2,webreconsuccesful=1

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.006 secs.
Sorting reachable states list...

Time for model construction: 0.007 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=128, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=128, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.001 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=0,accesstosensitivefiles=2,accesstoexecutearbitrarycode=2,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=0,accesstosensitivefiles=2,accesstoexecutearbitrarycode=2,webreconsuccesful=2

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
Prob1 (maxmin) took 3 iterations and 0.001 seconds.
target=64, inf=0, rest=64
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.001 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
Prob1 (maxmax) took 3 iterations and 0.0 seconds.
target=64, inf=0, rest=64
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 9 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 3 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: 200.0

Time for model checking: 0.001 seconds.

Result: 200.0 (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=1,accesstosensitivefiles=0,accesstoexecutearbitrarycode=0,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=1,accesstosensitivefiles=0,accesstoexecutearbitrarycode=0,webreconsuccesful=0

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=256, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=256, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.001 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=1,accesstosensitivefiles=0,accesstoexecutearbitrarycode=0,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=1,accesstosensitivefiles=0,accesstoexecutearbitrarycode=0,webreconsuccesful=1

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.006 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=256, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=256, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.001 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=1,accesstosensitivefiles=0,accesstoexecutearbitrarycode=0,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=1,accesstosensitivefiles=0,accesstoexecutearbitrarycode=0,webreconsuccesful=2

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.007 secs.
Sorting reachable states list...

Time for model construction: 0.008 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=256, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=256, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=1,accesstosensitivefiles=0,accesstoexecutearbitrarycode=1,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=1,accesstosensitivefiles=0,accesstoexecutearbitrarycode=1,webreconsuccesful=0

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.006 secs.
Sorting reachable states list...

Time for model construction: 0.006 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=256, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=256, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.001 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=1,accesstosensitivefiles=0,accesstoexecutearbitrarycode=1,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=1,accesstosensitivefiles=0,accesstoexecutearbitrarycode=1,webreconsuccesful=1

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.007 secs.
Sorting reachable states list...

Time for model construction: 0.007 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=256, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.001 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.001 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=256, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.001 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=1,accesstosensitivefiles=0,accesstoexecutearbitrarycode=1,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=1,accesstosensitivefiles=0,accesstoexecutearbitrarycode=1,webreconsuccesful=2

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.008 secs.
Sorting reachable states list...

Time for model construction: 0.008 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=256, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=256, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.001 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=1,accesstosensitivefiles=0,accesstoexecutearbitrarycode=2,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=1,accesstosensitivefiles=0,accesstoexecutearbitrarycode=2,webreconsuccesful=0

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.006 secs.
Sorting reachable states list...

Time for model construction: 0.006 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=256, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.001 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=256, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.001 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=1,accesstosensitivefiles=0,accesstoexecutearbitrarycode=2,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=1,accesstosensitivefiles=0,accesstoexecutearbitrarycode=2,webreconsuccesful=1

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.007 secs.
Sorting reachable states list...

Time for model construction: 0.008 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=256, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=256, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=1,accesstosensitivefiles=0,accesstoexecutearbitrarycode=2,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=1,accesstosensitivefiles=0,accesstoexecutearbitrarycode=2,webreconsuccesful=2

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.006 secs.
Sorting reachable states list...

Time for model construction: 0.006 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=256, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=256, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=1,accesstosensitivefiles=1,accesstoexecutearbitrarycode=0,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=1,accesstosensitivefiles=1,accesstoexecutearbitrarycode=0,webreconsuccesful=0

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.008 secs.
Sorting reachable states list...

Time for model construction: 0.009 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=256, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=256, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.001 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=1,accesstosensitivefiles=1,accesstoexecutearbitrarycode=0,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=1,accesstosensitivefiles=1,accesstoexecutearbitrarycode=0,webreconsuccesful=1

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.006 secs.
Sorting reachable states list...

Time for model construction: 0.007 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=256, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=256, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.001 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=1,accesstosensitivefiles=1,accesstoexecutearbitrarycode=0,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=1,accesstosensitivefiles=1,accesstoexecutearbitrarycode=0,webreconsuccesful=2

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.006 secs.
Sorting reachable states list...

Time for model construction: 0.006 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=256, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=256, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=1,accesstosensitivefiles=1,accesstoexecutearbitrarycode=1,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=1,accesstosensitivefiles=1,accesstoexecutearbitrarycode=1,webreconsuccesful=0

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.006 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=256, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=256, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=1,accesstosensitivefiles=1,accesstoexecutearbitrarycode=1,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=1,accesstosensitivefiles=1,accesstoexecutearbitrarycode=1,webreconsuccesful=1

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=256, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=256, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=1,accesstosensitivefiles=1,accesstoexecutearbitrarycode=1,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=1,accesstosensitivefiles=1,accesstoexecutearbitrarycode=1,webreconsuccesful=2

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.006 secs.
Sorting reachable states list...

Time for model construction: 0.006 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=256, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=256, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=1,accesstosensitivefiles=1,accesstoexecutearbitrarycode=2,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=1,accesstosensitivefiles=1,accesstoexecutearbitrarycode=2,webreconsuccesful=0

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.006 secs.
Sorting reachable states list...

Time for model construction: 0.006 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=256, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=256, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.001 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=1,accesstosensitivefiles=1,accesstoexecutearbitrarycode=2,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=1,accesstosensitivefiles=1,accesstoexecutearbitrarycode=2,webreconsuccesful=1

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.006 secs.
Sorting reachable states list...

Time for model construction: 0.006 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=256, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=256, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.002 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=1,accesstosensitivefiles=1,accesstoexecutearbitrarycode=2,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=1,accesstosensitivefiles=1,accesstoexecutearbitrarycode=2,webreconsuccesful=2

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.008 secs.
Sorting reachable states list...

Time for model construction: 0.008 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=256, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.001 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=256, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.001 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=1,accesstosensitivefiles=2,accesstoexecutearbitrarycode=0,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=1,accesstosensitivefiles=2,accesstoexecutearbitrarycode=0,webreconsuccesful=0

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.007 secs.
Sorting reachable states list...

Time for model construction: 0.007 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=128, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=128, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=1,accesstosensitivefiles=2,accesstoexecutearbitrarycode=0,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=1,accesstosensitivefiles=2,accesstoexecutearbitrarycode=0,webreconsuccesful=1

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.006 secs.
Sorting reachable states list...

Time for model construction: 0.008 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=128, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=128, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.002 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=1,accesstosensitivefiles=2,accesstoexecutearbitrarycode=0,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=1,accesstosensitivefiles=2,accesstoexecutearbitrarycode=0,webreconsuccesful=2

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.008 secs.
Sorting reachable states list...

Time for model construction: 0.008 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=128, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=128, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.001 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=1,accesstosensitivefiles=2,accesstoexecutearbitrarycode=1,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=1,accesstosensitivefiles=2,accesstoexecutearbitrarycode=1,webreconsuccesful=0

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.008 secs.
Sorting reachable states list...

Time for model construction: 0.008 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=128, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=128, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=1,accesstosensitivefiles=2,accesstoexecutearbitrarycode=1,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=1,accesstosensitivefiles=2,accesstoexecutearbitrarycode=1,webreconsuccesful=1

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.007 secs.
Sorting reachable states list...

Time for model construction: 0.008 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=128, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=128, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=1,accesstosensitivefiles=2,accesstoexecutearbitrarycode=1,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=1,accesstosensitivefiles=2,accesstoexecutearbitrarycode=1,webreconsuccesful=2

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.007 secs.
Sorting reachable states list...

Time for model construction: 0.007 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=128, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=128, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=1,accesstosensitivefiles=2,accesstoexecutearbitrarycode=2,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=1,accesstosensitivefiles=2,accesstoexecutearbitrarycode=2,webreconsuccesful=0

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.004 secs.
Sorting reachable states list...

Time for model construction: 0.004 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=128, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=128, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.001 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=1,accesstosensitivefiles=2,accesstoexecutearbitrarycode=2,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=1,accesstosensitivefiles=2,accesstoexecutearbitrarycode=2,webreconsuccesful=1

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.004 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=128, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.001 seconds.
Expected reachability took 0.001 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=128, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.001 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=1,accesstosensitivefiles=2,accesstoexecutearbitrarycode=2,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=1,accesstosensitivefiles=2,accesstoexecutearbitrarycode=2,webreconsuccesful=2

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=128, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=128, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.001 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.001 seconds.

Value in the initial state: Infinity

Time for model checking: 0.001 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=2,accesstosensitivefiles=0,accesstoexecutearbitrarycode=0,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=2,accesstosensitivefiles=0,accesstoexecutearbitrarycode=0,webreconsuccesful=0

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.006 secs.
Sorting reachable states list...

Time for model construction: 0.006 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
Prob1 (maxmin) took 3 iterations and 0.0 seconds.
target=128, inf=0, rest=128
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.001 seconds.
Expected reachability took 0.001 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
Prob1 (maxmax) took 3 iterations and 0.0 seconds.
target=128, inf=0, rest=128
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 11 iterations and 0.001 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 3 iterations and 0.0 seconds.
Expected reachability took 0.001 seconds.

Value in the initial state: 200.0

Time for model checking: 0.002 seconds.

Result: 200.0 (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=2,accesstosensitivefiles=0,accesstoexecutearbitrarycode=0,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=2,accesstosensitivefiles=0,accesstoexecutearbitrarycode=0,webreconsuccesful=1

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.006 secs.
Sorting reachable states list...

Time for model construction: 0.006 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=256, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=256, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=2,accesstosensitivefiles=0,accesstoexecutearbitrarycode=0,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=2,accesstosensitivefiles=0,accesstoexecutearbitrarycode=0,webreconsuccesful=2

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.007 secs.
Sorting reachable states list...

Time for model construction: 0.007 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
Prob1 (maxmin) took 3 iterations and 0.0 seconds.
target=128, inf=0, rest=128
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
Prob1 (maxmax) took 3 iterations and 0.0 seconds.
target=128, inf=0, rest=128
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 11 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 3 iterations and 0.001 seconds.
Expected reachability took 0.001 seconds.

Value in the initial state: 200.0

Time for model checking: 0.003 seconds.

Result: 200.0 (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=2,accesstosensitivefiles=0,accesstoexecutearbitrarycode=1,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=2,accesstosensitivefiles=0,accesstoexecutearbitrarycode=1,webreconsuccesful=0

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=256, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=256, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.001 seconds.

Value in the initial state: Infinity

Time for model checking: 0.001 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=2,accesstosensitivefiles=0,accesstoexecutearbitrarycode=1,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=2,accesstosensitivefiles=0,accesstoexecutearbitrarycode=1,webreconsuccesful=1

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=256, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=256, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.001 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=2,accesstosensitivefiles=0,accesstoexecutearbitrarycode=1,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=2,accesstosensitivefiles=0,accesstoexecutearbitrarycode=1,webreconsuccesful=2

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.007 secs.
Sorting reachable states list...

Time for model construction: 0.008 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=256, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=256, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=2,accesstosensitivefiles=0,accesstoexecutearbitrarycode=2,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=2,accesstosensitivefiles=0,accesstoexecutearbitrarycode=2,webreconsuccesful=0

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.006 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
Prob1 (maxmin) took 3 iterations and 0.001 seconds.
target=128, inf=0, rest=128
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.001 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
Prob1 (maxmax) took 3 iterations and 0.0 seconds.
target=128, inf=0, rest=128
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 11 iterations and 0.001 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 3 iterations and 0.0 seconds.
Expected reachability took 0.001 seconds.

Value in the initial state: 200.0

Time for model checking: 0.002 seconds.

Result: 200.0 (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=2,accesstosensitivefiles=0,accesstoexecutearbitrarycode=2,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=2,accesstosensitivefiles=0,accesstoexecutearbitrarycode=2,webreconsuccesful=1

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=256, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=256, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=2,accesstosensitivefiles=0,accesstoexecutearbitrarycode=2,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=2,accesstosensitivefiles=0,accesstoexecutearbitrarycode=2,webreconsuccesful=2

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.006 secs.
Sorting reachable states list...

Time for model construction: 0.006 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
Prob1 (maxmin) took 3 iterations and 0.0 seconds.
target=128, inf=0, rest=128
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
Prob1 (maxmax) took 3 iterations and 0.0 seconds.
target=128, inf=0, rest=128
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 11 iterations and 0.001 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 3 iterations and 0.0 seconds.
Expected reachability took 0.001 seconds.

Value in the initial state: 200.0

Time for model checking: 0.001 seconds.

Result: 200.0 (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=2,accesstosensitivefiles=1,accesstoexecutearbitrarycode=0,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=2,accesstosensitivefiles=1,accesstoexecutearbitrarycode=0,webreconsuccesful=0

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
Prob1 (maxmin) took 5 iterations and 0.001 seconds.
target=64, inf=0, rest=192
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.001 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
Prob1 (maxmax) took 5 iterations and 0.001 seconds.
target=64, inf=0, rest=192
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 11 iterations and 0.001 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 5 iterations and 0.0 seconds.
Expected reachability took 0.002 seconds.

Value in the initial state: 260.0

Time for model checking: 0.003 seconds.

Result: 260.0 (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=2,accesstosensitivefiles=1,accesstoexecutearbitrarycode=0,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=2,accesstosensitivefiles=1,accesstoexecutearbitrarycode=0,webreconsuccesful=1

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=256, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=256, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.001 seconds.
Expected reachability took 0.001 seconds.

Value in the initial state: Infinity

Time for model checking: 0.001 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=2,accesstosensitivefiles=1,accesstoexecutearbitrarycode=0,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=2,accesstosensitivefiles=1,accesstoexecutearbitrarycode=0,webreconsuccesful=2

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.006 secs.
Sorting reachable states list...

Time for model construction: 0.006 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
Prob1 (maxmin) took 5 iterations and 0.001 seconds.
target=64, inf=0, rest=192
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.001 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
Prob1 (maxmax) took 5 iterations and 0.0 seconds.
target=64, inf=0, rest=192
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 11 iterations and 0.001 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 5 iterations and 0.0 seconds.
Expected reachability took 0.002 seconds.

Value in the initial state: 260.0

Time for model checking: 0.003 seconds.

Result: 260.0 (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=2,accesstosensitivefiles=1,accesstoexecutearbitrarycode=1,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=2,accesstosensitivefiles=1,accesstoexecutearbitrarycode=1,webreconsuccesful=0

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.006 secs.
Sorting reachable states list...

Time for model construction: 0.006 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=256, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=256, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=2,accesstosensitivefiles=1,accesstoexecutearbitrarycode=1,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=2,accesstosensitivefiles=1,accesstoexecutearbitrarycode=1,webreconsuccesful=1

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=256, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=256, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.001 seconds.

Value in the initial state: Infinity

Time for model checking: 0.001 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=2,accesstosensitivefiles=1,accesstoexecutearbitrarycode=1,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=2,accesstosensitivefiles=1,accesstoexecutearbitrarycode=1,webreconsuccesful=2

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.004 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=256, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=256, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=2,accesstosensitivefiles=1,accesstoexecutearbitrarycode=2,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=2,accesstosensitivefiles=1,accesstoexecutearbitrarycode=2,webreconsuccesful=0

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
Prob1 (maxmin) took 5 iterations and 0.0 seconds.
target=64, inf=0, rest=192
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
Prob1 (maxmax) took 5 iterations and 0.001 seconds.
target=64, inf=0, rest=192
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 11 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 5 iterations and 0.001 seconds.
Expected reachability took 0.002 seconds.

Value in the initial state: 260.0

Time for model checking: 0.003 seconds.

Result: 260.0 (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=2,accesstosensitivefiles=1,accesstoexecutearbitrarycode=2,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=2,accesstosensitivefiles=1,accesstoexecutearbitrarycode=2,webreconsuccesful=1

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=256, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=256, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.001 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=2,accesstosensitivefiles=1,accesstoexecutearbitrarycode=2,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=2,accesstosensitivefiles=1,accesstoexecutearbitrarycode=2,webreconsuccesful=2

Computing reachable states... 256 states
Reachable states exploration and model construction done in 0.009 secs.
Sorting reachable states list...

Time for model construction: 0.009 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      256 (1 initial)
Transitions: 577
Choices:     577
Max/avg:     7/2.25
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
Prob1 (maxmin) took 5 iterations and 0.0 seconds.
target=64, inf=0, rest=192
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.001 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
Prob1 (maxmax) took 5 iterations and 0.0 seconds.
target=64, inf=0, rest=192
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 11 iterations and 0.001 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 5 iterations and 0.0 seconds.
Expected reachability took 0.001 seconds.

Value in the initial state: 260.0

Time for model checking: 0.002 seconds.

Result: 260.0 (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=2,accesstosensitivefiles=2,accesstoexecutearbitrarycode=0,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=2,accesstosensitivefiles=2,accesstoexecutearbitrarycode=0,webreconsuccesful=0

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
Prob1 (maxmin) took 3 iterations and 0.001 seconds.
target=64, inf=0, rest=64
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.001 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
Prob1 (maxmax) took 3 iterations and 0.0 seconds.
target=64, inf=0, rest=64
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 9 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 3 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: 200.0

Time for model checking: 0.001 seconds.

Result: 200.0 (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=2,accesstosensitivefiles=2,accesstoexecutearbitrarycode=0,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=2,accesstosensitivefiles=2,accesstoexecutearbitrarycode=0,webreconsuccesful=1

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=128, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=128, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=2,accesstosensitivefiles=2,accesstoexecutearbitrarycode=0,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=2,accesstosensitivefiles=2,accesstoexecutearbitrarycode=0,webreconsuccesful=2

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
Prob1 (maxmin) took 3 iterations and 0.0 seconds.
target=64, inf=0, rest=64
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
Prob1 (maxmax) took 3 iterations and 0.0 seconds.
target=64, inf=0, rest=64
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 9 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 3 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: 200.0

Time for model checking: 0.001 seconds.

Result: 200.0 (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=2,accesstosensitivefiles=2,accesstoexecutearbitrarycode=1,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=2,accesstosensitivefiles=2,accesstoexecutearbitrarycode=1,webreconsuccesful=0

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=128, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=128, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.001 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=2,accesstosensitivefiles=2,accesstoexecutearbitrarycode=1,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=2,accesstosensitivefiles=2,accesstoexecutearbitrarycode=1,webreconsuccesful=1

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=128, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=128, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=2,accesstosensitivefiles=2,accesstoexecutearbitrarycode=1,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=2,accesstosensitivefiles=2,accesstoexecutearbitrarycode=1,webreconsuccesful=2

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=128, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=128, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.001 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=2,accesstosensitivefiles=2,accesstoexecutearbitrarycode=2,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=2,accesstosensitivefiles=2,accesstoexecutearbitrarycode=2,webreconsuccesful=0

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
Prob1 (maxmin) took 3 iterations and 0.0 seconds.
target=64, inf=0, rest=64
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.001 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
Prob1 (maxmax) took 3 iterations and 0.0 seconds.
target=64, inf=0, rest=64
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 9 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 3 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: 200.0

Time for model checking: 0.001 seconds.

Result: 200.0 (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=2,accesstosensitivefiles=2,accesstoexecutearbitrarycode=2,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=2,accesstosensitivefiles=2,accesstoexecutearbitrarycode=2,webreconsuccesful=1

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=128, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=128, rest=0
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=1,accesstoreverseshell=2,accesstosensitivefiles=2,accesstoexecutearbitrarycode=2,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=1,accesstoreverseshell=2,accesstosensitivefiles=2,accesstoexecutearbitrarycode=2,webreconsuccesful=2

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
Prob1 (maxmin) took 3 iterations and 0.0 seconds.
target=64, inf=0, rest=64
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
Prob1 (maxmax) took 3 iterations and 0.0 seconds.
target=64, inf=0, rest=64
Computing the upper bound where 2.0 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 9 iterations and 0.001 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 3 iterations and 0.0 seconds.
Expected reachability took 0.001 seconds.

Value in the initial state: 200.0

Time for model checking: 0.001 seconds.

Result: 200.0 (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=0,accesstosensitivefiles=0,accesstoexecutearbitrarycode=0,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=0,accesstosensitivefiles=0,accesstoexecutearbitrarycode=0,webreconsuccesful=0

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
Prob1 (maxmin) took 1 iterations and 0.0 seconds.
target=128, inf=0, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
Prob1 (maxmax) took 1 iterations and 0.0 seconds.
target=128, inf=0, rest=0
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: 0.0

Time for model checking: 0.001 seconds.

Result: 0.0 (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=0,accesstosensitivefiles=0,accesstoexecutearbitrarycode=0,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=0,accesstosensitivefiles=0,accesstoexecutearbitrarycode=0,webreconsuccesful=1

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.006 secs.
Sorting reachable states list...

Time for model construction: 0.007 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=128, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=128, rest=0
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=0,accesstosensitivefiles=0,accesstoexecutearbitrarycode=0,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=0,accesstosensitivefiles=0,accesstoexecutearbitrarycode=0,webreconsuccesful=2

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.006 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
Prob1 (maxmin) took 1 iterations and 0.0 seconds.
target=128, inf=0, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
Prob1 (maxmax) took 1 iterations and 0.0 seconds.
target=128, inf=0, rest=0
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: 0.0

Time for model checking: 0.0 seconds.

Result: 0.0 (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=0,accesstosensitivefiles=0,accesstoexecutearbitrarycode=1,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=0,accesstosensitivefiles=0,accesstoexecutearbitrarycode=1,webreconsuccesful=0

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.004 secs.
Sorting reachable states list...

Time for model construction: 0.004 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=128, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=128, rest=0
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.001 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=0,accesstosensitivefiles=0,accesstoexecutearbitrarycode=1,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=0,accesstosensitivefiles=0,accesstoexecutearbitrarycode=1,webreconsuccesful=1

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=128, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=128, rest=0
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=0,accesstosensitivefiles=0,accesstoexecutearbitrarycode=1,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=0,accesstosensitivefiles=0,accesstoexecutearbitrarycode=1,webreconsuccesful=2

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=128, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=128, rest=0
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=0,accesstosensitivefiles=0,accesstoexecutearbitrarycode=2,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=0,accesstosensitivefiles=0,accesstoexecutearbitrarycode=2,webreconsuccesful=0

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
Prob1 (maxmin) took 1 iterations and 0.0 seconds.
target=128, inf=0, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
Prob1 (maxmax) took 1 iterations and 0.0 seconds.
target=128, inf=0, rest=0
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.001 seconds.

Value in the initial state: 0.0

Time for model checking: 0.001 seconds.

Result: 0.0 (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=0,accesstosensitivefiles=0,accesstoexecutearbitrarycode=2,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=0,accesstosensitivefiles=0,accesstoexecutearbitrarycode=2,webreconsuccesful=1

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.004 secs.
Sorting reachable states list...

Time for model construction: 0.004 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=128, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=128, rest=0
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=0,accesstosensitivefiles=0,accesstoexecutearbitrarycode=2,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=0,accesstosensitivefiles=0,accesstoexecutearbitrarycode=2,webreconsuccesful=2

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
Prob1 (maxmin) took 1 iterations and 0.0 seconds.
target=128, inf=0, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
Prob1 (maxmax) took 1 iterations and 0.0 seconds.
target=128, inf=0, rest=0
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: 0.0

Time for model checking: 0.0 seconds.

Result: 0.0 (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=0,accesstosensitivefiles=1,accesstoexecutearbitrarycode=0,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=0,accesstosensitivefiles=1,accesstoexecutearbitrarycode=0,webreconsuccesful=0

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
Prob1 (maxmin) took 3 iterations and 0.0 seconds.
target=64, inf=0, rest=64
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
Prob1 (maxmax) took 3 iterations and 0.0 seconds.
target=64, inf=0, rest=64
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 5 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 3 iterations and 0.0 seconds.
Expected reachability took 0.001 seconds.

Value in the initial state: 60.0

Time for model checking: 0.001 seconds.

Result: 60.0 (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=0,accesstosensitivefiles=1,accesstoexecutearbitrarycode=0,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=0,accesstosensitivefiles=1,accesstoexecutearbitrarycode=0,webreconsuccesful=1

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=128, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=128, rest=0
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.001 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=0,accesstosensitivefiles=1,accesstoexecutearbitrarycode=0,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=0,accesstosensitivefiles=1,accesstoexecutearbitrarycode=0,webreconsuccesful=2

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
Prob1 (maxmin) took 3 iterations and 0.0 seconds.
target=64, inf=0, rest=64
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
Prob1 (maxmax) took 3 iterations and 0.0 seconds.
target=64, inf=0, rest=64
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 5 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 3 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: 60.0

Time for model checking: 0.001 seconds.

Result: 60.0 (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=0,accesstosensitivefiles=1,accesstoexecutearbitrarycode=1,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=0,accesstosensitivefiles=1,accesstoexecutearbitrarycode=1,webreconsuccesful=0

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.004 secs.
Sorting reachable states list...

Time for model construction: 0.004 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=128, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=128, rest=0
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.001 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=0,accesstosensitivefiles=1,accesstoexecutearbitrarycode=1,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=0,accesstosensitivefiles=1,accesstoexecutearbitrarycode=1,webreconsuccesful=1

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.007 secs.
Sorting reachable states list...

Time for model construction: 0.007 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=128, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=128, rest=0
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.001 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=0,accesstosensitivefiles=1,accesstoexecutearbitrarycode=1,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=0,accesstosensitivefiles=1,accesstoexecutearbitrarycode=1,webreconsuccesful=2

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.004 secs.
Sorting reachable states list...

Time for model construction: 0.004 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=128, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=128, rest=0
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=0,accesstosensitivefiles=1,accesstoexecutearbitrarycode=2,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=0,accesstosensitivefiles=1,accesstoexecutearbitrarycode=2,webreconsuccesful=0

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
Prob1 (maxmin) took 3 iterations and 0.0 seconds.
target=64, inf=0, rest=64
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
Prob1 (maxmax) took 3 iterations and 0.0 seconds.
target=64, inf=0, rest=64
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 5 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 3 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: 60.0

Time for model checking: 0.0 seconds.

Result: 60.0 (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=0,accesstosensitivefiles=1,accesstoexecutearbitrarycode=2,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=0,accesstosensitivefiles=1,accesstoexecutearbitrarycode=2,webreconsuccesful=1

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.004 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=128, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=128, rest=0
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.001 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=0,accesstosensitivefiles=1,accesstoexecutearbitrarycode=2,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=0,accesstosensitivefiles=1,accesstoexecutearbitrarycode=2,webreconsuccesful=2

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
Prob1 (maxmin) took 3 iterations and 0.0 seconds.
target=64, inf=0, rest=64
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.001 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
Prob1 (maxmax) took 3 iterations and 0.0 seconds.
target=64, inf=0, rest=64
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 5 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 3 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: 60.0

Time for model checking: 0.001 seconds.

Result: 60.0 (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=0,accesstosensitivefiles=2,accesstoexecutearbitrarycode=0,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=0,accesstosensitivefiles=2,accesstoexecutearbitrarycode=0,webreconsuccesful=0

Computing reachable states... 64 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      64 (1 initial)
Transitions: 113
Choices:     113
Max/avg:     5/1.77
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
Prob1 (maxmin) took 1 iterations and 0.0 seconds.
target=64, inf=0, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.001 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
Prob1 (maxmax) took 1 iterations and 0.0 seconds.
target=64, inf=0, rest=0
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: 0.0

Time for model checking: 0.001 seconds.

Result: 0.0 (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=0,accesstosensitivefiles=2,accesstoexecutearbitrarycode=0,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=0,accesstosensitivefiles=2,accesstoexecutearbitrarycode=0,webreconsuccesful=1

Computing reachable states... 64 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      64 (1 initial)
Transitions: 113
Choices:     113
Max/avg:     5/1.77
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=64, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=64, rest=0
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=0,accesstosensitivefiles=2,accesstoexecutearbitrarycode=0,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=0,accesstosensitivefiles=2,accesstoexecutearbitrarycode=0,webreconsuccesful=2

Computing reachable states... 64 states
Reachable states exploration and model construction done in 0.004 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      64 (1 initial)
Transitions: 113
Choices:     113
Max/avg:     5/1.77
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
Prob1 (maxmin) took 1 iterations and 0.0 seconds.
target=64, inf=0, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
Prob1 (maxmax) took 1 iterations and 0.0 seconds.
target=64, inf=0, rest=0
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: 0.0

Time for model checking: 0.0 seconds.

Result: 0.0 (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=0,accesstosensitivefiles=2,accesstoexecutearbitrarycode=1,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=0,accesstosensitivefiles=2,accesstoexecutearbitrarycode=1,webreconsuccesful=0

Computing reachable states... 64 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      64 (1 initial)
Transitions: 113
Choices:     113
Max/avg:     5/1.77
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=64, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=64, rest=0
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=0,accesstosensitivefiles=2,accesstoexecutearbitrarycode=1,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=0,accesstosensitivefiles=2,accesstoexecutearbitrarycode=1,webreconsuccesful=1

Computing reachable states... 64 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      64 (1 initial)
Transitions: 113
Choices:     113
Max/avg:     5/1.77
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=64, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=64, rest=0
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=0,accesstosensitivefiles=2,accesstoexecutearbitrarycode=1,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=0,accesstosensitivefiles=2,accesstoexecutearbitrarycode=1,webreconsuccesful=2

Computing reachable states... 64 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      64 (1 initial)
Transitions: 113
Choices:     113
Max/avg:     5/1.77
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=64, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.001 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=64, rest=0
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.001 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=0,accesstosensitivefiles=2,accesstoexecutearbitrarycode=2,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=0,accesstosensitivefiles=2,accesstoexecutearbitrarycode=2,webreconsuccesful=0

Computing reachable states... 64 states
Reachable states exploration and model construction done in 0.004 secs.
Sorting reachable states list...

Time for model construction: 0.004 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      64 (1 initial)
Transitions: 113
Choices:     113
Max/avg:     5/1.77
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
Prob1 (maxmin) took 1 iterations and 0.0 seconds.
target=64, inf=0, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
Prob1 (maxmax) took 1 iterations and 0.0 seconds.
target=64, inf=0, rest=0
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: 0.0

Time for model checking: 0.0 seconds.

Result: 0.0 (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=0,accesstosensitivefiles=2,accesstoexecutearbitrarycode=2,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=0,accesstosensitivefiles=2,accesstoexecutearbitrarycode=2,webreconsuccesful=1

Computing reachable states... 64 states
Reachable states exploration and model construction done in 0.004 secs.
Sorting reachable states list...

Time for model construction: 0.004 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      64 (1 initial)
Transitions: 113
Choices:     113
Max/avg:     5/1.77
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=64, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=64, rest=0
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=0,accesstosensitivefiles=2,accesstoexecutearbitrarycode=2,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=0,accesstosensitivefiles=2,accesstoexecutearbitrarycode=2,webreconsuccesful=2

Computing reachable states... 64 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      64 (1 initial)
Transitions: 113
Choices:     113
Max/avg:     5/1.77
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
Prob1 (maxmin) took 1 iterations and 0.0 seconds.
target=64, inf=0, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
Prob1 (maxmax) took 1 iterations and 0.0 seconds.
target=64, inf=0, rest=0
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: 0.0

Time for model checking: 0.0 seconds.

Result: 0.0 (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=1,accesstosensitivefiles=0,accesstoexecutearbitrarycode=0,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=1,accesstosensitivefiles=0,accesstoexecutearbitrarycode=0,webreconsuccesful=0

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=128, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=128, rest=0
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=1,accesstosensitivefiles=0,accesstoexecutearbitrarycode=0,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=1,accesstosensitivefiles=0,accesstoexecutearbitrarycode=0,webreconsuccesful=1

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.006 secs.
Sorting reachable states list...

Time for model construction: 0.006 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=128, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=128, rest=0
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=1,accesstosensitivefiles=0,accesstoexecutearbitrarycode=0,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=1,accesstosensitivefiles=0,accesstoexecutearbitrarycode=0,webreconsuccesful=2

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.006 secs.
Sorting reachable states list...

Time for model construction: 0.006 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=128, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=128, rest=0
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.001 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=1,accesstosensitivefiles=0,accesstoexecutearbitrarycode=1,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=1,accesstosensitivefiles=0,accesstoexecutearbitrarycode=1,webreconsuccesful=0

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=128, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=128, rest=0
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=1,accesstosensitivefiles=0,accesstoexecutearbitrarycode=1,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=1,accesstosensitivefiles=0,accesstoexecutearbitrarycode=1,webreconsuccesful=1

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=128, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.001 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=128, rest=0
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.001 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=1,accesstosensitivefiles=0,accesstoexecutearbitrarycode=1,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=1,accesstosensitivefiles=0,accesstoexecutearbitrarycode=1,webreconsuccesful=2

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=128, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=128, rest=0
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=1,accesstosensitivefiles=0,accesstoexecutearbitrarycode=2,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=1,accesstosensitivefiles=0,accesstoexecutearbitrarycode=2,webreconsuccesful=0

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.006 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=128, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=128, rest=0
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=1,accesstosensitivefiles=0,accesstoexecutearbitrarycode=2,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=1,accesstosensitivefiles=0,accesstoexecutearbitrarycode=2,webreconsuccesful=1

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=128, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=128, rest=0
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=1,accesstosensitivefiles=0,accesstoexecutearbitrarycode=2,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=1,accesstosensitivefiles=0,accesstoexecutearbitrarycode=2,webreconsuccesful=2

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=128, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=128, rest=0
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=1,accesstosensitivefiles=1,accesstoexecutearbitrarycode=0,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=1,accesstosensitivefiles=1,accesstoexecutearbitrarycode=0,webreconsuccesful=0

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.008 secs.
Sorting reachable states list...

Time for model construction: 0.008 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=128, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=128, rest=0
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=1,accesstosensitivefiles=1,accesstoexecutearbitrarycode=0,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=1,accesstosensitivefiles=1,accesstoexecutearbitrarycode=0,webreconsuccesful=1

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.006 secs.
Sorting reachable states list...

Time for model construction: 0.006 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=128, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=128, rest=0
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=1,accesstosensitivefiles=1,accesstoexecutearbitrarycode=0,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=1,accesstosensitivefiles=1,accesstoexecutearbitrarycode=0,webreconsuccesful=2

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=128, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=128, rest=0
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=1,accesstosensitivefiles=1,accesstoexecutearbitrarycode=1,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=1,accesstosensitivefiles=1,accesstoexecutearbitrarycode=1,webreconsuccesful=0

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=128, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=128, rest=0
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=1,accesstosensitivefiles=1,accesstoexecutearbitrarycode=1,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=1,accesstosensitivefiles=1,accesstoexecutearbitrarycode=1,webreconsuccesful=1

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=128, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=128, rest=0
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=1,accesstosensitivefiles=1,accesstoexecutearbitrarycode=1,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=1,accesstosensitivefiles=1,accesstoexecutearbitrarycode=1,webreconsuccesful=2

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=128, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=128, rest=0
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=1,accesstosensitivefiles=1,accesstoexecutearbitrarycode=2,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=1,accesstosensitivefiles=1,accesstoexecutearbitrarycode=2,webreconsuccesful=0

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=128, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=128, rest=0
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=1,accesstosensitivefiles=1,accesstoexecutearbitrarycode=2,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=1,accesstosensitivefiles=1,accesstoexecutearbitrarycode=2,webreconsuccesful=1

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=128, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=128, rest=0
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.001 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=1,accesstosensitivefiles=1,accesstoexecutearbitrarycode=2,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=1,accesstosensitivefiles=1,accesstoexecutearbitrarycode=2,webreconsuccesful=2

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.004 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=128, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=128, rest=0
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=1,accesstosensitivefiles=2,accesstoexecutearbitrarycode=0,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=1,accesstosensitivefiles=2,accesstoexecutearbitrarycode=0,webreconsuccesful=0

Computing reachable states... 64 states
Reachable states exploration and model construction done in 0.004 secs.
Sorting reachable states list...

Time for model construction: 0.004 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      64 (1 initial)
Transitions: 113
Choices:     113
Max/avg:     5/1.77
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=64, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=64, rest=0
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=1,accesstosensitivefiles=2,accesstoexecutearbitrarycode=0,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=1,accesstosensitivefiles=2,accesstoexecutearbitrarycode=0,webreconsuccesful=1

Computing reachable states... 64 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      64 (1 initial)
Transitions: 113
Choices:     113
Max/avg:     5/1.77
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=64, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.001 seconds.
Expected reachability took 0.001 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=64, rest=0
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.001 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=1,accesstosensitivefiles=2,accesstoexecutearbitrarycode=0,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=1,accesstosensitivefiles=2,accesstoexecutearbitrarycode=0,webreconsuccesful=2

Computing reachable states... 64 states
Reachable states exploration and model construction done in 0.004 secs.
Sorting reachable states list...

Time for model construction: 0.004 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      64 (1 initial)
Transitions: 113
Choices:     113
Max/avg:     5/1.77
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=64, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=64, rest=0
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=1,accesstosensitivefiles=2,accesstoexecutearbitrarycode=1,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=1,accesstosensitivefiles=2,accesstoexecutearbitrarycode=1,webreconsuccesful=0

Computing reachable states... 64 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      64 (1 initial)
Transitions: 113
Choices:     113
Max/avg:     5/1.77
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=64, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=64, rest=0
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=1,accesstosensitivefiles=2,accesstoexecutearbitrarycode=1,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=1,accesstosensitivefiles=2,accesstoexecutearbitrarycode=1,webreconsuccesful=1

Computing reachable states... 64 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      64 (1 initial)
Transitions: 113
Choices:     113
Max/avg:     5/1.77
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=64, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=64, rest=0
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=1,accesstosensitivefiles=2,accesstoexecutearbitrarycode=1,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=1,accesstosensitivefiles=2,accesstoexecutearbitrarycode=1,webreconsuccesful=2

Computing reachable states... 64 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      64 (1 initial)
Transitions: 113
Choices:     113
Max/avg:     5/1.77
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=64, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=64, rest=0
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=1,accesstosensitivefiles=2,accesstoexecutearbitrarycode=2,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=1,accesstosensitivefiles=2,accesstoexecutearbitrarycode=2,webreconsuccesful=0

Computing reachable states... 64 states
Reachable states exploration and model construction done in 0.004 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      64 (1 initial)
Transitions: 113
Choices:     113
Max/avg:     5/1.77
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=64, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=64, rest=0
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=1,accesstosensitivefiles=2,accesstoexecutearbitrarycode=2,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=1,accesstosensitivefiles=2,accesstoexecutearbitrarycode=2,webreconsuccesful=1

Computing reachable states... 64 states
Reachable states exploration and model construction done in 0.004 secs.
Sorting reachable states list...

Time for model construction: 0.004 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      64 (1 initial)
Transitions: 113
Choices:     113
Max/avg:     5/1.77
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=64, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=64, rest=0
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=1,accesstosensitivefiles=2,accesstoexecutearbitrarycode=2,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=1,accesstosensitivefiles=2,accesstoexecutearbitrarycode=2,webreconsuccesful=2

Computing reachable states... 64 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      64 (1 initial)
Transitions: 113
Choices:     113
Max/avg:     5/1.77
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=64, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=64, rest=0
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.001 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=2,accesstosensitivefiles=0,accesstoexecutearbitrarycode=0,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=2,accesstosensitivefiles=0,accesstoexecutearbitrarycode=0,webreconsuccesful=0

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.004 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
Prob1 (maxmin) took 1 iterations and 0.0 seconds.
target=128, inf=0, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
Prob1 (maxmax) took 1 iterations and 0.0 seconds.
target=128, inf=0, rest=0
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: 0.0

Time for model checking: 0.0 seconds.

Result: 0.0 (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=2,accesstosensitivefiles=0,accesstoexecutearbitrarycode=0,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=2,accesstosensitivefiles=0,accesstoexecutearbitrarycode=0,webreconsuccesful=1

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=128, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=128, rest=0
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=2,accesstosensitivefiles=0,accesstoexecutearbitrarycode=0,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=2,accesstosensitivefiles=0,accesstoexecutearbitrarycode=0,webreconsuccesful=2

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.006 secs.
Sorting reachable states list...

Time for model construction: 0.006 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
Prob1 (maxmin) took 1 iterations and 0.0 seconds.
target=128, inf=0, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
Prob1 (maxmax) took 1 iterations and 0.0 seconds.
target=128, inf=0, rest=0
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: 0.0

Time for model checking: 0.0 seconds.

Result: 0.0 (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=2,accesstosensitivefiles=0,accesstoexecutearbitrarycode=1,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=2,accesstosensitivefiles=0,accesstoexecutearbitrarycode=1,webreconsuccesful=0

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=128, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=128, rest=0
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.001 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=2,accesstosensitivefiles=0,accesstoexecutearbitrarycode=1,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=2,accesstosensitivefiles=0,accesstoexecutearbitrarycode=1,webreconsuccesful=1

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=128, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=128, rest=0
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=2,accesstosensitivefiles=0,accesstoexecutearbitrarycode=1,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=2,accesstosensitivefiles=0,accesstoexecutearbitrarycode=1,webreconsuccesful=2

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.013 secs.
Sorting reachable states list...

Time for model construction: 0.014 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=128, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=128, rest=0
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.001 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=2,accesstosensitivefiles=0,accesstoexecutearbitrarycode=2,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=2,accesstosensitivefiles=0,accesstoexecutearbitrarycode=2,webreconsuccesful=0

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.008 secs.
Sorting reachable states list...

Time for model construction: 0.008 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
Prob1 (maxmin) took 1 iterations and 0.0 seconds.
target=128, inf=0, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
Prob1 (maxmax) took 1 iterations and 0.0 seconds.
target=128, inf=0, rest=0
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: 0.0

Time for model checking: 0.0 seconds.

Result: 0.0 (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=2,accesstosensitivefiles=0,accesstoexecutearbitrarycode=2,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=2,accesstosensitivefiles=0,accesstoexecutearbitrarycode=2,webreconsuccesful=1

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.008 secs.
Sorting reachable states list...

Time for model construction: 0.008 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=128, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=128, rest=0
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=2,accesstosensitivefiles=0,accesstoexecutearbitrarycode=2,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=2,accesstosensitivefiles=0,accesstoexecutearbitrarycode=2,webreconsuccesful=2

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.007 secs.
Sorting reachable states list...

Time for model construction: 0.007 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
Prob1 (maxmin) took 1 iterations and 0.0 seconds.
target=128, inf=0, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
Prob1 (maxmax) took 1 iterations and 0.0 seconds.
target=128, inf=0, rest=0
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: 0.0

Time for model checking: 0.0 seconds.

Result: 0.0 (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=2,accesstosensitivefiles=1,accesstoexecutearbitrarycode=0,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=2,accesstosensitivefiles=1,accesstoexecutearbitrarycode=0,webreconsuccesful=0

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.008 secs.
Sorting reachable states list...

Time for model construction: 0.008 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
Prob1 (maxmin) took 3 iterations and 0.0 seconds.
target=64, inf=0, rest=64
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
Prob1 (maxmax) took 3 iterations and 0.0 seconds.
target=64, inf=0, rest=64
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 5 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 3 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: 60.0

Time for model checking: 0.0 seconds.

Result: 60.0 (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=2,accesstosensitivefiles=1,accesstoexecutearbitrarycode=0,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=2,accesstosensitivefiles=1,accesstoexecutearbitrarycode=0,webreconsuccesful=1

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.007 secs.
Sorting reachable states list...

Time for model construction: 0.007 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=128, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=128, rest=0
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=2,accesstosensitivefiles=1,accesstoexecutearbitrarycode=0,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=2,accesstosensitivefiles=1,accesstoexecutearbitrarycode=0,webreconsuccesful=2

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.008 secs.
Sorting reachable states list...

Time for model construction: 0.008 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
Prob1 (maxmin) took 3 iterations and 0.0 seconds.
target=64, inf=0, rest=64
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
Prob1 (maxmax) took 3 iterations and 0.0 seconds.
target=64, inf=0, rest=64
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 5 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 3 iterations and 0.001 seconds.
Expected reachability took 0.001 seconds.

Value in the initial state: 60.0

Time for model checking: 0.001 seconds.

Result: 60.0 (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=2,accesstosensitivefiles=1,accesstoexecutearbitrarycode=1,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=2,accesstosensitivefiles=1,accesstoexecutearbitrarycode=1,webreconsuccesful=0

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.008 secs.
Sorting reachable states list...

Time for model construction: 0.009 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=128, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=128, rest=0
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=2,accesstosensitivefiles=1,accesstoexecutearbitrarycode=1,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=2,accesstosensitivefiles=1,accesstoexecutearbitrarycode=1,webreconsuccesful=1

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=128, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=128, rest=0
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=2,accesstosensitivefiles=1,accesstoexecutearbitrarycode=1,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=2,accesstosensitivefiles=1,accesstoexecutearbitrarycode=1,webreconsuccesful=2

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=128, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=128, rest=0
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=2,accesstosensitivefiles=1,accesstoexecutearbitrarycode=2,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=2,accesstosensitivefiles=1,accesstoexecutearbitrarycode=2,webreconsuccesful=0

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
Prob1 (maxmin) took 3 iterations and 0.0 seconds.
target=64, inf=0, rest=64
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
Prob1 (maxmax) took 3 iterations and 0.0 seconds.
target=64, inf=0, rest=64
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 5 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 3 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: 60.0

Time for model checking: 0.0 seconds.

Result: 60.0 (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=2,accesstosensitivefiles=1,accesstoexecutearbitrarycode=2,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=2,accesstosensitivefiles=1,accesstoexecutearbitrarycode=2,webreconsuccesful=1

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=128, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=128, rest=0
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=2,accesstosensitivefiles=1,accesstoexecutearbitrarycode=2,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=2,accesstosensitivefiles=1,accesstoexecutearbitrarycode=2,webreconsuccesful=2

Computing reachable states... 128 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      128 (1 initial)
Transitions: 257
Choices:     257
Max/avg:     6/2.01
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
Prob1 (maxmin) took 3 iterations and 0.001 seconds.
target=64, inf=0, rest=64
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.001 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
Prob1 (maxmax) took 3 iterations and 0.0 seconds.
target=64, inf=0, rest=64
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 5 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 3 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: 60.0

Time for model checking: 0.001 seconds.

Result: 60.0 (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=2,accesstosensitivefiles=2,accesstoexecutearbitrarycode=0,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=2,accesstosensitivefiles=2,accesstoexecutearbitrarycode=0,webreconsuccesful=0

Computing reachable states... 64 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      64 (1 initial)
Transitions: 113
Choices:     113
Max/avg:     5/1.77
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
Prob1 (maxmin) took 1 iterations and 0.0 seconds.
target=64, inf=0, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
Prob1 (maxmax) took 1 iterations and 0.0 seconds.
target=64, inf=0, rest=0
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: 0.0

Time for model checking: 0.0 seconds.

Result: 0.0 (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=2,accesstosensitivefiles=2,accesstoexecutearbitrarycode=0,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=2,accesstosensitivefiles=2,accesstoexecutearbitrarycode=0,webreconsuccesful=1

Computing reachable states... 64 states
Reachable states exploration and model construction done in 0.007 secs.
Sorting reachable states list...

Time for model construction: 0.007 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      64 (1 initial)
Transitions: 113
Choices:     113
Max/avg:     5/1.77
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=64, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=64, rest=0
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=2,accesstosensitivefiles=2,accesstoexecutearbitrarycode=0,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=2,accesstosensitivefiles=2,accesstoexecutearbitrarycode=0,webreconsuccesful=2

Computing reachable states... 64 states
Reachable states exploration and model construction done in 0.007 secs.
Sorting reachable states list...

Time for model construction: 0.007 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      64 (1 initial)
Transitions: 113
Choices:     113
Max/avg:     5/1.77
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
Prob1 (maxmin) took 1 iterations and 0.0 seconds.
target=64, inf=0, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
Prob1 (maxmax) took 1 iterations and 0.0 seconds.
target=64, inf=0, rest=0
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: 0.0

Time for model checking: 0.0 seconds.

Result: 0.0 (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=2,accesstosensitivefiles=2,accesstoexecutearbitrarycode=1,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=2,accesstosensitivefiles=2,accesstoexecutearbitrarycode=1,webreconsuccesful=0

Computing reachable states... 64 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      64 (1 initial)
Transitions: 113
Choices:     113
Max/avg:     5/1.77
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=64, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=64, rest=0
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=2,accesstosensitivefiles=2,accesstoexecutearbitrarycode=1,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=2,accesstosensitivefiles=2,accesstoexecutearbitrarycode=1,webreconsuccesful=1

Computing reachable states... 64 states
Reachable states exploration and model construction done in 0.006 secs.
Sorting reachable states list...

Time for model construction: 0.006 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      64 (1 initial)
Transitions: 113
Choices:     113
Max/avg:     5/1.77
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=64, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=64, rest=0
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=2,accesstosensitivefiles=2,accesstoexecutearbitrarycode=1,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=2,accesstosensitivefiles=2,accesstoexecutearbitrarycode=1,webreconsuccesful=2

Computing reachable states... 64 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      64 (1 initial)
Transitions: 113
Choices:     113
Max/avg:     5/1.77
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=64, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=64, rest=0
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.001 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.001 seconds.

Value in the initial state: Infinity

Time for model checking: 0.001 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=2,accesstosensitivefiles=2,accesstoexecutearbitrarycode=2,webreconsuccesful=0

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=2,accesstosensitivefiles=2,accesstoexecutearbitrarycode=2,webreconsuccesful=0

Computing reachable states... 64 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      64 (1 initial)
Transitions: 113
Choices:     113
Max/avg:     5/1.77
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
Prob1 (maxmin) took 1 iterations and 0.0 seconds.
target=64, inf=0, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
Prob1 (maxmax) took 1 iterations and 0.0 seconds.
target=64, inf=0, rest=0
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: 0.0

Time for model checking: 0.0 seconds.

Result: 0.0 (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=2,accesstosensitivefiles=2,accesstoexecutearbitrarycode=2,webreconsuccesful=1

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=2,accesstosensitivefiles=2,accesstoexecutearbitrarycode=2,webreconsuccesful=1

Computing reachable states... 64 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      64 (1 initial)
Transitions: 113
Choices:     113
Max/avg:     5/1.77
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
target=0, inf=64, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
target=0, inf=64, rest=0
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: Infinity

Time for model checking: 0.0 seconds.

Result: Infinity (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

---------------------------------------------------------------------

Model checking: <<attacker,defender>>R{"attacker"}min=? [ F "terminate" ]+R{"defender"}min=? [ F "terminate" ]
Model constants: accesstomysql=2,accesstoreverseshell=2,accesstosensitivefiles=2,accesstoexecutearbitrarycode=2,webreconsuccesful=2

Warning: Switching to explicit engine to allow strategy generation.

Building model...
Model constants: accesstomysql=2,accesstoreverseshell=2,accesstosensitivefiles=2,accesstoexecutearbitrarycode=2,webreconsuccesful=2

Computing reachable states... 64 states
Reachable states exploration and model construction done in 0.005 secs.
Sorting reachable states list...

Time for model construction: 0.005 seconds.

Warning: Deadlocks detected and fixed in 1 states

Type:        SMG
States:      64 (1 initial)
Transitions: 113
Choices:     113
Max/avg:     5/1.77
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmin)...
Prob1 (maxmin) took 1 iterations and 0.0 seconds.
target=64, inf=0, rest=0
Computing the upper bound where 0.0 is used instead of 0.0
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmax)...
Value iteration (minmax) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.
Building reward structure...

Starting expected reachability...
Starting Prob1 (maxmax)...
Prob1 (maxmax) took 1 iterations and 0.0 seconds.
target=64, inf=0, rest=0
Computing the upper bound where 1.5 is used instead of 0.0
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Computed an over-approximation of the solution (in 0 seconds), this will now be used to get the solution
Starting value iteration (minmin)...
Value iteration (minmin) took 1 iterations and 0.0 seconds.
Expected reachability took 0.0 seconds.

Value in the initial state: 0.0

Time for model checking: 0.001 seconds.

Result: 0.0 (exact floating point)

Exporting strategy as a dot file to file "experiments/experiment4/results/Defender/Defender.dot"...

Exporting results as list (CSV) to file "experiments/experiment4/results/Defender/Defender.csv"...

---------------------------------------------------------------------

Note: There were 486 warnings during computation.

	Command being timed: "../prism-games-3.2.1-linux64-x86/bin/prism -javamaxmem 12g -cuddmaxmem 2g experiments/experiment4/prism/Defender.prism experiments/experiment4/prism/defender.props -prop 1 -const accesstomysql=0:2,accesstoreverseshell=0:2,accesstosensitivefiles=0:2,accesstoexecutearbitrarycode=0:2,webreconsuccesful=0:2 -exportresults experiments/experiment4/results/Defender/Defender.csv:csv -exportstrat experiments/experiment4/results/Defender/Defender.dot"
	User time (seconds): 8.80
	System time (seconds): 0.74
	Percent of CPU this job got: 321%
	Elapsed (wall clock) time (h:mm:ss or m:ss): 0:02.97
	Average shared text size (kbytes): 0
	Average unshared data size (kbytes): 0
	Average stack size (kbytes): 0
	Average total size (kbytes): 0
	Maximum resident set size (kbytes): 459468
	Average resident set size (kbytes): 0
	Major (requiring I/O) page faults: 11
	Minor (reclaiming a frame) page faults: 42328
	Voluntary context switches: 11357
	Involuntary context switches: 91
	Swaps: 0
	File system inputs: 288
	File system outputs: 2024
	Socket messages sent: 0
	Socket messages received: 0
	Signals delivered: 0
	Page size (bytes): 4096
	Exit status: 0
